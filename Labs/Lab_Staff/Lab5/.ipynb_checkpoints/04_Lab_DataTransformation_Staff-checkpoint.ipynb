{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineering Analytics and Machine Learning Lab 4\n",
    "## for Specialist Diploma in Internet of Things\n",
    "\n",
    "### Author’s Name: Teo Kok Keong\n",
    "\n",
    "### Property of Temasek Polytechnic, Copyright ©.\n",
    "### For circulation within Temasek Polytechnic only.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Normalization\n",
    "\n",
    "Lets try range scaling on the DAILYDATA_S24_201801.csv weather data. We are trying to find whether DailyRainfallTotal have any relationship with MeanTemperature. Before we even do anything, lets see how is the raw data like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('DAILYDATA_S24_201801.csv')  #load the data\n",
    "df.head()   #have a preview of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot scatter plot of both DailyRainfallTotal with MeanTemperature vs Day on the same graph\n",
    "plt.plot(df.Day, df.MeanTemperature,'-o')\n",
    "plt.plot(df.Day, df.DailyRainfallTotal,'-o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we can see that there is not much change in the mean temperature, it is nearly a straight line. We are unablet o observe any obvious relationship between the two parameters. This is because we are comparing two parameters of different scale, which is comparing apple with orange. Daily Rainfall total value varied from 0 to as high as more than 40. However, temperature only varied between the narrow band of maybe 25 to 31 or 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minT=min(df.MeanTemperature)   #find the min of MeanTemperature\n",
    "maxT=max(df.MeanTemperature)   #find the max of MeanTemperature\n",
    "df['NorT']=(df.MeanTemperature-minT)/(maxT-minT)   #Scale to 0 t 1 of Mean Temperature\n",
    "#Scale to 0 to 1 for Daily Rainfall Total\n",
    "df['NorR']=(df.DailyRainfallTotal-min(df.DailyRainfallTotal))/(max(df.DailyRainfallTotal)-min(df.DailyRainfallTotal)) \n",
    "df.head() #Preview the data again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot scatter plot of both rescaled DailyRainfallTotal with MeanTemperature vs Day on the same graph\n",
    "plt.plot(df.Day, df.NorT,'-o')\n",
    "plt.plot(df.Day, df.NorR,'-o')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationshi become obvious for observation after rescale both data to 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot scatter plot of both DailyRainfallTotal with MeanTemperature vs Day on the same graph\n",
    "plt.plot(df.Day, df.MeanWindSpeed,'-o')\n",
    "plt.plot(df.Day, df.DailyRainfallTotal,'-o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale to 0 to 1 for Daily Rainfall Total\n",
    "df['NorW']=(df.MeanWindSpeed-min(df.MeanWindSpeed))/(max(df.MeanWindSpeed)-min(df.MeanWindSpeed)) \n",
    "df.head() #Preview the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot scatter plot of both rescaled DailyRainfallTotal with MeanTemperature vs Day on the same graph\n",
    "plt.plot(df.Day, df.NorW,'-o')\n",
    "plt.plot(df.Day, df.NorR,'-o')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any comment?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Try with DAILYDATA_S24_201801.csv with standardization transformation to find the relationship btween\n",
    "- Total Daily Rainfall and MeanTemperature\n",
    "- Total Daily Rainfall and MeanWindSpeed\n",
    "\n",
    "Hint: Use np.mean() and np.std() to find mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanT=np.mean(df.MeanTemperature)   #find the min of MeanTemperature\n",
    "stdT=np.std(df.MeanTemperature)   #find the max of MeanTemperature\n",
    "df['NorT2']=(df.MeanTemperature-minT)/(maxT-minT)   #Scale to 0 t 1 of Mean Temperature\n",
    "#Scale to 0 to 1 for Daily Rainfall Total\n",
    "df['NorR2']=df.DailyRainfallTotal-np.mean(df.DailyRainfallTotal)/np.std(df.DailyRainfallTotal) \n",
    "df.head() #Preview the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot scatter plot of both rescaled DailyRainfallTotal with MeanTemperature vs Day on the same graph\n",
    "plt.plot(df.Day, df.NorT2,'-o')\n",
    "plt.plot(df.Day, df.NorR2,'-o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale to 0 to 1 for Daily Rainfall Total\n",
    "df['NorW2']=df.MeanWindSpeed-np.mean(df.MeanWindSpeed)/np.std(df.MeanWindSpeed) \n",
    "df.head() #Preview the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot scatter plot of both rescaled DailyRainfallTotal with MeanTemperature vs Day on the same graph\n",
    "plt.plot(df.Day, df.NorW2,'-o')\n",
    "plt.plot(df.Day, df.NorR2,'-o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it as useful in this as re-scaling to 0 to 1?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Data Aggregration\n",
    "\n",
    "Data aggregation is a type of data and information mining process where data is searched, gathered and presented in a report-based, summarized format to achieve specific business objectives or processes and/or conduct human analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=pd.read_csv('remote_v3.csv')  #load the data\n",
    "dd['time']=pd.to_datetime(dd['time'],format='%Y-%m-%d %H:%M:%S+08:00',utc=True) #convert string to datetime\n",
    "#tt=pd.to_datetime(dd['time'],format='%Y-%m-%d %H:%M:%S',utc=True) #convert string to datetime\n",
    "#dd['time']=(dd['time'].astype(np.int64)) /100000000   #convert to second\n",
    "dd['onlytime']=pd.to_datetime(dd.time.dt.floor('h')).dt.time\n",
    "dd.set_index('time', inplace=True)\n",
    "plt.plot(dd.index,dd['value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.describe() #we could always use the describe method to understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data, convert the datetime and change to index. We also plot a graph but this tell us nothing. Since this is in a class room, we ould expect the occupancy of the venue to change according to day of week (monday, tuesday...) and timing. We do have the time but no information on the day of week. Howeverr, we have the date so we could generate a new column that indicate the day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['dayofweek']=dd.index.dayofweek\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section only to illustration some aggregation method available\n",
    "print(\"result of sum:\")\n",
    "print(dd.sum()) #sum  accordingly to column\n",
    "print(\"result of mean:\")\n",
    "print(dd.mean())  #mean  accordingly to colum\n",
    "\n",
    "#by default aggregation return results within each column\n",
    "#by specifying the axis argument, we can instead aggregate within each row:\n",
    "\n",
    "print(dd.mean(axis='columns').head()) #in this case does not make sense but we are only illustrating the feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have summary the data by rows or columns, most of the time we need to aggregate with GroupBy to find insight into the data. \n",
    "\n",
    "Back to analysising the remote eye data. We probably want to groupby dayofweek and apply mean operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets group by day of  week and view it statistical properties\n",
    "dd.groupby('dayofweek').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we would perform aggregate on the data\n",
    "gdd=dd.groupby(['dayofweek','onlytime']).aggregate([np.mean, min])\n",
    "print(gdd)\n",
    "print(gdd.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we would perform aggregate on the data\n",
    "gdd=dd.groupby(['dayofweek','onlytime']).aggregate([np.mean])\n",
    "\n",
    "#find the max mean value to normalize the data for comparision\n",
    "bb=[]\n",
    "\n",
    "for i in range(7):\n",
    "    b=max(gdd.loc[i,'value']['mean'])\n",
    "    bb.append(b)\n",
    "    \n",
    "bb_max=max(bb)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ll=[0]*len(gdd.xs(0))\n",
    "\n",
    "for i in range(7):\n",
    "    ll=[i]*len(gdd.xs(i))\n",
    "    ax=plt.scatter(ll,gdd.xs(i).index,c=gdd.loc[i,'value']['mean']/bb_max,vmax=1)\n",
    "    \n",
    "plt.colorbar()\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of aggregate built-in statistic functions\n",
    "\n",
    "**Function**|**Description**\n",
    ":-----:|:-----:\n",
    "count|Number of non-null observations\n",
    "sum|Sum of values\n",
    "mean|Mean of values\n",
    "mad|Mean absolute deviation\n",
    "median|Arithmetic median of values\n",
    "min|Minimum\n",
    "max|Maximum\n",
    "mode|Mode\n",
    "abs|Absolute Value\n",
    "prod|Product of values\n",
    "std|Unbiased standard deviation\n",
    "var|Unbiased variance\n",
    "sem|Unbiased standard error of the mean\n",
    "skew|Unbiased skewness (3rd moment)\n",
    "kurt|Unbiased kurtosis (4th moment)\n",
    "quantile|Sample quantile (value at %)\n",
    "cumsum|Cumulative sum\n",
    "cumprod|Cumulative product\n",
    "cummax|Cumulative maximum\n",
    "cummin|Cumulative minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(711)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(14, 16.5)\n",
    "\n",
    "# equivalent but more general\n",
    "axx=plt.subplot(7, 1, 1)\n",
    "\n",
    "\n",
    "axx.plot(gdd.loc[0].index,gdd.loc[0,'value']['mean'])\n",
    "axx2=plt.subplot(7,1, 2)\n",
    "axx2.plot(gdd.loc[1].index,gdd.loc[1,'value']['mean'])\n",
    "axx3=plt.subplot(7,1, 3)\n",
    "axx3.plot(gdd.loc[2].index,gdd.loc[2,'value']['mean'])\n",
    "axx4=plt.subplot(7,1, 4)\n",
    "axx4.plot(gdd.loc[3].index,gdd.loc[3,'value']['mean'])\n",
    "axx5=plt.subplot( 7,1, 5)\n",
    "axx5.plot(gdd.loc[4].index,gdd.loc[4,'value']['mean'])\n",
    "axx6=plt.subplot(7,1, 6)\n",
    "axx6.plot(gdd.loc[5].index,gdd.loc[5,'value']['mean'])\n",
    "axx7=plt.subplot(7,1, 7)\n",
    "axx7.plot(gdd.loc[6].index,gdd.loc[6,'value']['mean'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=[]\n",
    "for i in range(7):\n",
    "    b=max(gdd.loc[i,'value']['mean'])\n",
    "    bb.append(b)\n",
    "    \n",
    "bb_max=max(bb)\n",
    "\n",
    "#plt.subplot(711)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 7.5)\n",
    "\n",
    "# equivalent but more general\n",
    "#axx=plt.subplot(7, 1, 1)\n",
    "\n",
    "\n",
    "plt.plot(gdd.loc[0].index,gdd.loc[0,'value']['mean']/bb_max,label='Monday')\n",
    "#axx2=plt.subplot(7,1, 2)\n",
    "plt.plot(gdd.loc[1].index,gdd.loc[1,'value']['mean']/bb_max,label='Tuesday')\n",
    "#axx3=plt.subplot(7,1, 3)\n",
    "plt.plot(gdd.loc[2].index,gdd.loc[2,'value']['mean']/bb_max,label='Wednesday')\n",
    "#axx4=plt.subplot(7,1, 4)\n",
    "plt.plot(gdd.loc[3].index,gdd.loc[3,'value']['mean']/bb_max,label='Thursday')\n",
    "#axx5=plt.subplot( 7,1, 5)\n",
    "plt.plot(gdd.loc[4].index,gdd.loc[4,'value']['mean']/bb_max,label='Friday')\n",
    "#axx6=plt.subplot(7,1, 6)\n",
    "plt.plot(gdd.loc[5].index,gdd.loc[5,'value']['mean']/bb_max,label='Saturday')\n",
    "#axx7=plt.subplot(7,1, 7)\n",
    "plt.plot(gdd.loc[6].index,gdd.loc[6,'value']['mean']/bb_max,label='Sunday')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Mean Value')\n",
    "plt.title('Graphs of Scaled Mean values vs time for different day of week')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "\n",
    "Load the iris dataset from sklearn (code would be provided below), the data set would be saved in variable data. Thare are two sets of data, data.data (data itself) and data.target (the bred code).\n",
    "\n",
    "- use data.data and data.target to found one dataframe\n",
    "- Compute mean, max, min of each parameter for each bred type (0,1,2,). Which aggregated value would be more suitable to classified the data according to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "data=load_iris()\n",
    "targetname=['Setosa','Versicolour','Virginica']\n",
    "\n",
    "df=pd.DataFrame(data.data)\n",
    "\n",
    "df.columns=['sepallen','sepalwidth','pedallen','pedalwidth']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']=data.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=df.groupby(['target']).aggregate([np.mean,max,min])\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "oad the amazonaws credit data from this site [https://rodeo-tutorials.s3.amazonaws.com/data/credit-data-non-null.csv](https://rodeo-tutorials.s3.amazonaws.com/data/credit-data-non-null.csv)\n",
    "\n",
    "- Slice a subset of data that consist of 'serious_dlqin2yrs', 'age', 'monthly_income'\n",
    "- Compute the mean parameters for each serious_dlqin2yrs category of the subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"https://rodeo-tutorials.s3.amazonaws.com/data/credit-data-non-null.csv\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=df4[['serious_dlqin2yrs', 'age', 'monthly_income']]\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.groupby(\"serious_dlqin2yrs\").aggregate([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.groupby(\"age\").aggregate([np.mean])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
